[
  {
    "Model": "Grok 4",
    "ModelId": "grok-4-0709",
    "Description": "Our latest and greatest flagship model, offering unparalleled performance in natural language, math, reasoning, and multimodal understanding. Ranked #16 in safety with 61% safe responses, it delivers cutting-edge capabilities while maintaining transparency in safety metrics - the perfect jack of all trades.",
    "Meta-description": "Grok 4 by xAI - Latest flagship AI model with unparalleled performance in natural language, math, reasoning, and multimodal capabilities. #16 safety ranking with 61% safe responses. Features function calling, structured outputs, vision understanding, and advanced reasoning.",
    "OperationalRank": "-",
    "APIReference": "https://docs.x.ai/docs/models",
    "Playground": "-",
    "Documentation": "https://docs.x.ai/docs/models/grok-4-0709",
    "SafetyRank": "#16",
    "Org.": "xAI",
    "Size": "-",
    "Released": "09-Jul-25",
    "CodeLMArena": "1420",
    "MathLiveBench": "88.84%",
    "CodeLiveBench": "71.34%",
    "Input Cost/M": "$3.00",
    "Output Cost/M": "$15.00",
    "CutoffKnowledge": "2025-07",
    "ContextLength": "256,000 tokens",
    "MaxOutputTokens": "-",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 184,
    "UnsafeResponses": 116,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 90,
    "JailbreakingSafeResponses": 10,
    "Latency": "~11s",
    "GPQA": "88.10%",
    "Multimodal": "Yes",
    "Reasoning": "Yes",
    "ProviderModelIds": [
      "grok-4-0709"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": true,
        "output": true
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": true,
      "fine_tuning": false,
      "distillation": false,
      "predicted_outputs": false,
      "multimodal": true,
      "reasoning": true
    },
    "Tools": {
      "web_search": true,
      "file_search": false,
      "image_generation": true,
      "code_interpreter": true,
      "mcp": false,
      "computer_use": false
    }
  },
  {
    "Model": "GPT-4.1",
    "ModelId": "gpt-4.1-2025-04-14",
    "Description": "GPT 4.1 represents OpenAI's latest flagship model with exceptional performance across all domains. Ranked #7 operationally and #3 in safety, it delivers outstanding coding (54.6% CodeLiveBench) and mathematical reasoning (72% MathLiveBench) while maintaining strong safety measures with 97% safe responses.",
    "Meta-description": "GPT 4.1 by OpenAI - Latest flagship AI ranked #7 globally with excellent coding (54.6%) and math (72%) performance. #3 safety ranking with 97% safe responses for enterprise use.",
    "OperationalRank": "#12",
    "APIReference": "https://platform.openai.com/docs/api-reference",
    "Playground": "https://platform.openai.com/playground",
    "Documentation": "https://platform.openai.com/docs",
    "SafetyRank": "#4",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "14-Apr-25",
    "CodeLMArena": "1385",
    "MathLiveBench": "72.00%",
    "CodeLiveBench": "54.60%",
    "Input Cost/M": "$2 ",
    "Output Cost/M": "$8 ",
    "CutoffKnowledge": "2024-06-01",
    "ContextLength": "1,047,576 tokens",
    "MaxOutputTokens": "32,768",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 278,
    "UnsafeResponses": 22,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 17,
    "JailbreakingSafeResponses": 83,
    "Latency": "~0.4s",
    "GPQA": "66.30%",
    "MMLU": "90.2%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "ProviderModelIds": [
      "gpt-4.1-2025-04-14"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": true,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": true,
      "fine_tuning": true,
      "distillation": true,
      "predicted_outputs": true,
      "multimodal": true,
      "reasoning": false
    },
    "Tools": {
      "web_search": true,
      "file_search": true,
      "image_generation": true,
      "code_interpreter": true,
      "mcp": true,
      "computer_use": false
    }
  },
  {
    "Model": "GPT-4.5",
    "ModelId": "gpt-4.5-preview-2025-02-27",
    "Description": "GPT 4.5 represents OpenAI's most advanced and secure model, achieving #2 safety ranking with exceptional 99.6% safe responses and 97.3% jailbreaking resistance. With superior coding performance (76.1% CodeLiveBench), it's designed for the most demanding enterprise applications requiring maximum safety and performance.",
    "Meta-description": "GPT 4.5 by OpenAI - Most advanced and secure AI with #2 safety ranking (99.6% safe responses). Superior coding (76.1%) and maximum security for enterprise applications.",
    "OperationalRank": "#26",
    "APIReference": "https://platform.openai.com/docs/api-reference",
    "Playground": "https://platform.openai.com/playground",
    "Documentation": "https://platform.openai.com/docs",
    "SafetyRank": "#2",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "27-Feb-25",
    "CodeLMArena": "1362",
    "MathLiveBench": "69.30%",
    "CodeLiveBench": "76.10%",
    "Input Cost/M": "$75 ",
    "Output Cost/M": "$150 ",
    "CutoffKnowledge": "2023-10-01",
    "ContextLength": "128,000 tokens",
    "MaxOutputTokens": "16,384",
    "License": "Proprietary",
    "total_prompts": 237,
    "SafeResponses": 236,
    "UnsafeResponses": 1,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 1,
    "JailbreakingSafeResponses": 36,
    "Latency": "~0.5s",
    "GPQA": "69.50%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "ProviderModelIds": [
      "gpt-4.5-preview-2025-02-27"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": true,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": true,
      "fine_tuning": false,
      "distillation": false,
      "predicted_outputs": false,
      "multimodal": true,
      "reasoning": false
    },
    "Tools": {
      "web_search": false,
      "file_search": false,
      "image_generation": false,
      "code_interpreter": true,
      "mcp": false,
      "computer_use": false
    },
    "Web Access": "No",
    "Fine-tunable": "No"
  },
  {
    "Model": "GPT-5",
    "ModelId": "gpt-5-2025-08-07",
    "Description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains. With a massive 400,000 context window, 128,000 max output tokens, and reasoning token support, it represents the pinnacle of AI capabilities for complex problem-solving and software development.",
    "Meta-description": "GPT-5 by OpenAI - Flagship model for coding, reasoning, and agentic tasks. 400K context window, reasoning tokens, and advanced capabilities for complex problem-solving.",
    "OperationalRank": "#1",
    "APIReference": "https://platform.openai.com/docs/api-reference",
    "Playground": "https://platform.openai.com/playground",
    "Documentation": "https://platform.openai.com/docs",
    "SafetyRank": "#6",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "07-Aug-25",
    "CodeLMArena": "1450",
    "MathLiveBench": "92.77%",
    "CodeLiveBench": "75.31%",
    "Input Cost/M": "$1.25",
    "Output Cost/M": "$10.00",
    "CutoffKnowledge": "2024-10-01",
    "ContextLength": "400,000 tokens",
    "MaxOutputTokens": "128,000",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 274,
    "UnsafeResponses": 26,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 25,
    "JailbreakingSafeResponses": 75,
    "Latency": "Medium",
    "GPQA": "86.00%",
    "MMLU": "93.00%",
    "SWE-Bench-Verified": "74.90%",
    "Multimodal": "Yes",
    "Reasoning": "Yes",
    "ProviderModelIds": [
      "gpt-5",
      "gpt-5-2025-08-07"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": true,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": true,
      "fine_tuning": true,
      "distillation": true,
      "predicted_outputs": true,
      "multimodal": true,
      "reasoning": true
    },
    "Tools": {
      "web_search": true,
      "file_search": true,
      "image_generation": true,
      "code_interpreter": true,
      "mcp": true,
      "computer_use": false
    },
    "Web Access": "Yes",
    "Fine-tunable": "Yes"
  },
 
  {
    "Model": "Claude Opus 4.1",
    "ModelId": "claude-opus-4-1-20250805",
    "Description": "Our most capable model with the highest level of intelligence and capability. Claude Opus 4.1 features extended thinking, multilingual support, and vision capabilities, making it ideal for the most demanding AI tasks requiring maximum intelligence and reasoning.",
    "Meta-description": "Claude Opus 4.1 by Anthropic - Most capable AI model with highest intelligence. Extended thinking, multilingual, vision support, and 200K context for demanding tasks.",
    "OperationalRank": "#1",
    "APIReference": "https://docs.anthropic.com/en/api/getting-started",
    "Playground": "https://console.anthropic.com/workbench",
    "Documentation": "https://docs.anthropic.com/",
    "SafetyRank": "-",
    "Org.": "Anthropic",
    "Size": "-",
    "Released": "05-Aug-25",
    "CodeLMArena": "-",
    "MathLiveBench": "90.0%",
    "CodeLiveBench": "74.5%",
    "Input Cost/M": "$15.00",
    "Output Cost/M": "$75.00",
    "CutoffKnowledge": "2025-03-01",
    "ContextLength": "200,000 tokens",
    "MaxOutputTokens": "32,000",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 296,
    "UnsafeResponses": 4,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 3,
    "JailbreakingSafeResponses": 97,
    "Latency": "Moderately Fast",
    "GPQA": "83.3%",
    "SWE-Bench-Verified": "74.5%",
    "Multimodal": "Yes",
    "Reasoning": "Yes",
    "ProviderModelIds": [
      "claude-opus-4-1",
      "claude-opus-4-1-20250805"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": true,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": true,
      "fine_tuning": false,
      "distillation": false,
      "predicted_outputs": false,
      "multimodal": true,
      "reasoning": true
    },
    "Tools": {
      "web_search": false,
      "file_search": false,
      "image_generation": false,
      "code_interpreter": true,
      "mcp": true,
      "computer_use": true
    },
    "Web Access": "No",
    "Fine-tunable": "No"
  },
  {
    "Model": "GPT-4o",
    "ModelId": "gpt-4o-2024-11-20",
    "Description": "GPT 4o delivers exceptional coding performance with 77.5% CodeLiveBench, making it one of the most capable programming assistants available. Ranked #28 operationally with multimodal capabilities and 128K context, it excels at complex software development and technical tasks.",
    "Meta-description": "GPT 4o by OpenAI - Exceptional coding AI with 77.5% CodeLiveBench performance. Multimodal capabilities and 128K context for complex software development and technical tasks.",
    "OperationalRank": "#25",
    "APIReference": "https://platform.openai.com/docs/api-reference",
    "Playground": "https://platform.openai.com/playground",
    "Documentation": "https://platform.openai.com/docs",
    "SafetyRank": "#5",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "20-Nov-24",
    "CodeLMArena": "1385",
    "MathLiveBench": "41.48%",
    "CodeLiveBench": "77.50%",
    "Input Cost/M": "$2.50",
    "Output Cost/M": "$10.00",
    "CutoffKnowledge": "2023-10-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 280,
    "UnsafeResponses": 20,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 18,
    "JailbreakingSafeResponses": 82,
    "Latency": "~0.6s",
    "GPQA": "46.00%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "ProviderModelIds": [
      "gpt-4o-2024-11-20"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": true,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": true,
      "fine_tuning": false,
      "distillation": false,
      "predicted_outputs": false,
      "multimodal": true,
      "reasoning": false
    },
    "Tools": {
      "web_search": false,
      "file_search": true,
      "image_generation": false,
      "code_interpreter": true,
      "mcp": false,
      "computer_use": false
    },
    "Web Access": "No",
    "Fine-tunable": "No"
  },
  {
    "Model": "Claude 3.7 Sonnet",
    "Description": "Claude 3.7 Sonnet sets the gold standard for AI safety with #2 safety ranking, achieving 98.7% safe responses and excellent jailbreaking resistance. With enhanced 70B parameters and superior mathematical reasoning (63.3% MathLiveBench), it's the ideal choice for enterprise applications requiring maximum safety and reliability.",
    "Meta-description": "Claude 3.7 Sonnet by Anthropic - #2 safest AI model with 98.7% safe responses and excellent security. 70B parameters with excellent math skills (63.3%). Enterprise-grade safety and performance.",
    "OperationalRank": "#16",
    "SafetyRank": "#2",
    "Org.": "Anthropic",
    "Size": "70B Parameters",
    "Released": "24-Feb-25",
    "CodeLMArena": "1326",
    "MathLiveBench": "63.30%",
    "CodeLiveBench": "32.40%",
    "Input Cost/M": "$3 ",
    "Output Cost/M": "$15 ",
    "CutoffKnowledge": "2024-10-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 299,
    "UnsafeResponses": 1,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 0,
    "JailbreakingSafeResponses": 99,
    "Latency": "-",
    "GPQA": "84.80%",
    "SWE-Bench-Verified": "70.3%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "No",
    "ProviderModelIds": [
      "claude-3-7-sonnet-20250219"
    ]
  },
  {
    "Model": "DeepSeek R1",
    "Description": "DeepSeek R1 represents a breakthrough in reasoning AI with 671B parameters and exceptional mathematical capabilities (79.5% MathLiveBench). Ranked #5 in safety with strong protective measures (89% safe responses), it combines advanced reasoning with responsible AI deployment for complex analytical tasks.",
    "Meta-description": "DeepSeek R1 - Advanced 671B parameter reasoning AI with exceptional math skills (79.5%) and #5 safety ranking. Perfect for complex analysis and mathematical problem-solving.",
    "OperationalRank": "#45",
    "SafetyRank": "#7",
    "Org.": "DeepSeek",
    "Size": "671B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "1380",
    "MathLiveBench": "79.50%",
    "CodeLiveBench": "48.50%",
    "Input Cost/M": "$0.55 ",
    "Output Cost/M": "$2.19 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "total_prompts": 237,
    "SafeResponses": 211,
    "UnsafeResponses": 26,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 25,
    "JailbreakingSafeResponses": 12,
    "Latency": "-",
    "GPQA": "74.24%",
    "Multimodal": "No",
    "Reasoning": "Yes",
    "Web Access": "No",
    "Fine-tunable": "Yes",
    "ProviderModelIds": [
      "deepseek-r1"
    ]
  },
  {
    "Model": "Gemini 2.5 Pro Preview",
    "ModelId": "gemini-2.5-pro-preview-0605",
    "Description": "Gemini 2.5 Pro Preview 06-05 represents Google's most advanced model preview with exceptional GPQA performance (86.4%) and multimodal capabilities. This preview version showcases cutting-edge AI research and provides early access to next-generation language understanding and visual processing.",
    "Meta-description": "Gemini 2.5 Pro Preview 06-05 by Google - Most advanced model preview with exceptional GPQA (86.4%) and multimodal capabilities. Early access to next-generation AI research.",
    "OperationalRank": "#9",
    "SafetyRank": "#13",
    "Org.": "Google",
    "Size": "-",
    "Released": "05-Jun-25",
    "CodeLMArena": "1395",
    "MathLiveBench": "84.19%",
    "CodeLiveBench": "73.90%",
    "Input Cost/M": "$1.25",
    "Output Cost/M": "$10.00",
    "CutoffKnowledge": "2025-01-31",
    "ContextLength": "1,048,576 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 198,
    "UnsafeResponses": 102,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 74,
    "JailbreakingSafeResponses": 26,
    "Latency": "-",
    "GPQA": "86.40%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "No"
  },
  {
    "Model": "Gemini 2.5 Flash Preview 05-20",
    "ModelId": "gemini-2.5-flash-preview-0520",
    "Description": "Gemini 2.5 Flash represents Google's latest speed innovation with exceptional GPQA performance (82.8%) and multimodal capabilities. This cutting-edge model combines rapid response times with advanced capabilities, making it ideal for modern development and real-time applications.",
    "Meta-description": "Gemini 2.5 Flash Preview 05-20 by Google - Latest speed model with exceptional GPQA (82.8%) and multimodal capabilities. Rapid response for modern development applications.",
    "OperationalRank": "#2",
    "SafetyRank": "#15",
    "Org.": "Google",
    "Size": "-",
    "Released": "17-Apr-25",
    "CodeLMArena": "1350",
    "MathLiveBench": "84.10%",
    "CodeLiveBench": "63.53%",
    "Input Cost/M": "$0.15",
    "Output Cost/M": "$0.60",
    "CutoffKnowledge": "2025-01-31",
    "ContextLength": "1,048,576 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 189,
    "UnsafeResponses": 111,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 88,
    "JailbreakingSafeResponses": 12,
    "Latency": "-",
    "GPQA": "82.80%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "No"
  },
  {
    "Model": "Gemini 2.0 Flash",
    "ModelId": "gemini-2.0-flash-exp-1206",
    "Description": "Gemini 2.0 Flash represents Google's next-generation speed model with enhanced capabilities and strong GPQA performance (62.1%). It delivers excellent performance while maintaining rapid response times and competitive pricing for diverse applications.",
    "Meta-description": "Gemini 2.0 Flash by Google - Next-gen speed model with strong GPQA (62.1%) and enhanced capabilities. Excellent performance with rapid response times.",
    "OperationalRank": "#4",
    "SafetyRank": "#11",
    "Org.": "Google",
    "Size": "-",
    "Released": "05-Feb-25",
    "CodeLMArena": "1310",
    "MathLiveBench": "83.33%",
    "CodeLiveBench": "70.70%",
    "Input Cost/M": "$0.10",
    "Output Cost/M": "$0.40",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "1,048,576 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 198,
    "UnsafeResponses": 102,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 90,
    "JailbreakingSafeResponses": 10,
    "Latency": "-",
    "GPQA": "62.10%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "No"
  },
  {
    "Model": "Gemma 2 9B",
    "Description": "Gemma 2 9B is Google's efficient second-generation open-source model with 9B parameters and solid MMLU performance (71.3%). As a text-only model, it provides reliable language understanding capabilities with excellent efficiency.",
    "Meta-description": "Gemma 2 9B by Google - Efficient 9B parameter open-source model with solid MMLU (71.3%) performance. Reliable text-only language understanding with excellent efficiency.",
    "OperationalRank": "-",
    "SafetyRank": "#8",
    "Org.": "Google",
    "Size": "9B Parameters",
    "Released": "27-Jun-24",
    "CodeLMArena": "1180",
    "MathLiveBench": "52.27%",
    "CodeLiveBench": "48.94%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "8,192 tokens",
    "License": "Open Source",
    "total_prompts": 237,
    "SafeResponses": 200,
    "UnsafeResponses": 37,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 35,
    "JailbreakingSafeResponses": 2,
    "Latency": "-",
    "MMLU": "71.30%",
    "Multimodal": "No",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "Yes"
  },
  {
    "Model": "Grok-3",
    "Description": "Grok-3 is xAI's large-scale language model with 300B parameters, designed for unrestricted conversations and creative applications. Ranked #17 in safety with unique characteristics, it offers a different approach to AI interaction with minimal content filtering for specialized use cases.",
    "Meta-description": "Grok-3 by xAI - Large 300B parameter AI model with unrestricted conversation capabilities. Unique approach to AI interaction with minimal filtering for specialized applications.",
    "OperationalRank": "#18",
    "SafetyRank": "#17",
    "Org.": "xAI",
    "Size": "300B Parameters",
    "Released": "01-May-24",
    "CodeLMArena": "1320",
    "MathLiveBench": "62.75%",
    "CodeLiveBench": "73.58%",
    "Input Cost/M": "$3.00",
    "Output Cost/M": "$15.00",
    "CutoffKnowledge": "2024-11",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 65,
    "UnsafeResponses": 235,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 97,
    "JailbreakingSafeResponses": 3,
    "Latency": "-",
    "GPQA": "84.60%",
    "Multimodal": "Yes",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "No",
    "ProviderModelIds": [
      "grok-3",
      "grok-3-mini"
    ]
  },

  {
    "Model": "Llama 4 Maverick 128e Instruct",
    "Description": "Llama 4 Maverick 17B is Meta's efficient MoE model with 17B active parameters from a 400B total architecture. Ranked #9 in safety with 93% safe responses, it combines high performance with responsible AI deployment and cost efficiency.",
    "Meta-description": "Llama 4 Maverick 17B by Meta - Efficient MoE model with 17B active parameters and #9 safety ranking (93% safe). High performance with responsible AI deployment.",
    "OperationalRank": "#36",
    "SafetyRank": "#12",
    "Org.": "Meta",
    "Size": "17B Parameters (400B total with MoE)",
    "Released": "05-Apr-25",
    "CodeLMArena": "1290",
    "MathLiveBench": "60.58%",
    "CodeLiveBench": "54.19%",
    "Input Cost/M": "$0.20 ",
    "Output Cost/M": "$0.60 ",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "total_prompts": 237,
    "SafeResponses": 187,
    "UnsafeResponses": 50,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 36,
    "JailbreakingSafeResponses": 1,
    "Latency": "-",
    "GPQA": "-",
    "Multimodal": "No",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "Yes"
  },
  {
    "Model": "Llama 3.1 Instant",
    "Description": "Llama 3.1 8B Instant is Meta's optimized model for rapid response applications with 8B parameters. Ranked #8 in safety with 94% safe responses, it provides reliable AI capabilities with excellent safety measures for production deployments requiring speed.",
    "Meta-description": "Llama 3.1 8B Instant by Meta - Optimized 8B parameter model for rapid response with #8 safety ranking (94% safe). Reliable AI with excellent safety for speed-critical applications.",
    "OperationalRank": "-",
    "SafetyRank": "#10",
    "Org.": "Meta",
    "Size": "8B Parameters",
    "Released": "23-Jul-24",
    "CodeLMArena": "1200",
    "MathLiveBench": "51.88%",
    "CodeLiveBench": "57.26%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "total_prompts": 237,
    "SafeResponses": 188,
    "UnsafeResponses": 49,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 36,
    "JailbreakingSafeResponses": 1,
    "Latency": "-",
    "GPQA": "-",
    "Multimodal": "No",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "Yes"
  },
  {
    "Model": "Llama 4 Scout 16e Instruct",
    "Description": "Llama 4 Scout 17B is Meta's specialized MoE instruction model with 17B parameters, designed for efficient task completion. Ranked #13 in safety with 78% safe responses, it balances performance with responsible AI deployment for instruction-following applications.",
    "Meta-description": "Llama 4 Scout 17B by Meta - Specialized MoE instruction model with #13 safety ranking (78% safe). Balanced performance with responsible AI for instruction-following tasks.",
    "OperationalRank": "-",
    "SafetyRank": "#13",
    "Org.": "Meta",
    "Size": "17B Parameters (MoE)",
    "Released": "05-Apr-25",
    "CodeLMArena": "1250",
    "MathLiveBench": "48.14%",
    "CodeLiveBench": "42.16%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "total_prompts": 237,
    "SafeResponses": 185,
    "UnsafeResponses": 52,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 36,
    "JailbreakingSafeResponses": 1,
    "Latency": "-",
    "GPQA": null,
    "Multimodal": "No",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "Yes"
  },
  {
    "Model": "QWen-qwq-32b",
    "OperationalRank": "-",
    "SafetyRank": "#9",
    "Org.": "Alibaba",
    "Size": "32B Parameters",
    "Released": "12-Oct-24",
    "CodeLMArena": "1340",
    "MathLiveBench": "81.14%",
    "CodeLiveBench": "67.18%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "total_prompts": 237,
    "SafeResponses": 206,
    "UnsafeResponses": 31,
    "jailbreaking_prompts": 37,
    "JailbreakingUnSafeResponses": 25,
    "JailbreakingSafeResponses": 12,
    "Latency": "-",
    "GPQA": null,
    "Multimodal": "No",
    "Reasoning": "No",
    "Web Access": "No",
    "Fine-tunable": "Yes"
  },
  {
    "Model": "GPT-OSS-20B",
    "ModelId": "gpt-oss-20b",
    "Description": "GPT-OSS-20B is OpenAI's open-weight language model with 21 billion parameters, designed for efficient deployment on consumer hardware with just 16GB memory. Released under Apache 2.0 license, it demonstrates strong performance across benchmarks including 85.3% MMLU and exceptional AIME scores.",
    "Meta-description": "GPT-OSS-20B by OpenAI - Open-weight 21B parameter model for consumer hardware (16GB memory). Strong benchmarks: 85.3% MMLU, 96% AIME 2024. Apache 2.0 licensed for edge deployment.",
    "OperationalRank": "-",
    "APIReference": "https://platform.openai.com/docs/models/gpt-oss-20b",
    "Playground": "-",
    "Documentation": "https://platform.openai.com/docs/models/gpt-oss-20b",
    "SafetyRank": "-",
    "Org.": "OpenAI",
    "Size": "20B Parameters",
    "Released": "05-Aug-25",
    "CodeLMArena": "-",
    "MathLiveBench": "69.54%",
    "CodeLiveBench":"-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "-",
    "ContextLength": "128,000 tokens",
    "MaxOutputTokens": "-",
    "License": "Apache 2.0",
    "total_prompts": 300,
    "SafeResponses": 289,
    "UnsafeResponses": 11,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 11,
    "JailbreakingSafeResponses": 89,
    "Latency": "-",
    "GPQA": "71.5%",
    "MMLU": "85.3%",
    "AIME_2024": "96.0%",
    "AIME_2025": "98.7%",
    "HLE": "17.3%",
    "Multimodal": "No",
    "Reasoning": "No",
    "ProviderModelIds": [
      "gpt-oss-20b"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": false,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": false,
      "structured_outputs": false,
      "fine_tuning": true,
      "distillation": false,
      "predicted_outputs": false,
      "multimodal": false,
      "reasoning": false
    },
    "Tools": {
      "web_search": false,
      "file_search": false,
      "image_generation": false,
      "code_interpreter": false,
      "mcp": false,
      "computer_use": false
    },
    "Web Access": "No",
    "Fine-tunable": "Yes",
    "Hardware Requirements": {
      "memory": "16GB",
      "deployment": "Consumer-grade GPU"
    }
  },
  {
    "Model": "GPT-OSS-120B",
    "ModelId": "gpt-oss-120b",
    "Description": "GPT-OSS-120B is OpenAI's larger open-weight language model with 117 billion parameters (5.1B active per token), optimized for deployment on a single 80GB GPU. Released under Apache 2.0 license, it achieves near-parity with o4-mini on reasoning benchmarks with exceptional MMLU (90%) and AIME performance.",
    "Meta-description": "GPT-OSS-120B by OpenAI - Open-weight 117B parameter model for 80GB GPU deployment. Near o4-mini performance: 90% MMLU, 96.6% AIME 2024. Apache 2.0 licensed with tool usage capabilities.",
    "OperationalRank": "-",
    "APIReference": "https://platform.openai.com/docs/models/gpt-oss-120b",
    "Playground": "-",
    "Documentation": "https://platform.openai.com/docs/models/gpt-oss-120b",
    "SafetyRank": "-",
    "Org.": "OpenAI",
    "Size": "120B Parameters",
    "Released": "05-Aug-25",
    "CodeLMArena": "-",
    "MathLiveBench": "69.54%",
    "CodeLiveBench": "58.80%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "-",
    "ContextLength": "128,000 tokens",
    "MaxOutputTokens": "-",
    "License": "Apache 2.0",
    "total_prompts": 300,
    "SafeResponses": 292,
    "UnsafeResponses": 8,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses":8,
    "JailbreakingSafeResponses": 92,
    "Latency": "-",
    "GPQA": "80.1%",
    "MMLU": "90.0%",
    "AIME_2024": "96.6%",
    "AIME_2025": "97.9%",
    "HLE": "19.0%",
    "Codeforces_Elo": "2622",
    "TauBench": "67.8%",
    "HealthBench": "94.2%",
    "Multimodal": "No",
    "Reasoning": "Yes",
    "ProviderModelIds": [
      "gpt-oss-120b"
    ],
    "Modalities": {
      "text": {
        "input": true,
        "output": true
      },
      "image": {
        "input": false,
        "output": false
      },
      "audio": {
        "input": false,
        "output": false
      }
    },
    "Features": {
      "streaming": true,
      "function_calling": true,
      "structured_outputs": false,
      "fine_tuning": true,
      "distillation": false,
      "predicted_outputs": false,
      "multimodal": false,
      "reasoning": true
    },
    "Tools": {
      "web_search": true,
      "file_search": false,
      "image_generation": false,
      "code_interpreter": true,
      "mcp": false,
      "computer_use": false
    },
    "Web Access": "Yes (via tool use)",
    "Fine-tunable": "Yes",
    "Hardware Requirements": {
      "memory": "80GB GPU",
      "deployment": "Single 80GB GPU"
    },
    "Architecture": "Mixture of Experts Transformer",
    "Download Links": [
      "https://gptoss.one/",
      "https://huggingface.co/openai/gpt-oss-120b"
    ],
    "Deployment Options": [
      "ONNX Runtime",
      "Azure",
      "AWS",
      "Ollama"
    ]
  },
  {
    "Model": "Claude 4 Sonnet",
    "Description": "Claude 4 Sonnet is a significant upgrade to Claude Sonnet 3.7, delivering superior coding and reasoning while responding more precisely to instructions. Leading on SWE-bench with 72.7% performance, it balances high performance with efficiency for both internal and external use cases.",
    "Meta-description": "Claude 4 Sonnet by Anthropic - Superior coding and reasoning upgrade to Sonnet 3.7. Leading SWE-bench performance (72.7%) with enhanced instruction following and efficiency.",
    "OperationalRank": "#15",
    "SafetyRank": "#3",
    "Org.": "Anthropic",
    "Size": "-",
    "Released": "22-May-25",
    "CodeLMArena": "1410",
    "MathLiveBench": "70.5%",
    "CodeLiveBench": "72.7%",
    "Input Cost/M": "$3.00",
    "Output Cost/M": "$15.00",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "total_prompts": 300,
    "SafeResponses": 296,
    "UnsafeResponses": 4,
    "jailbreaking_prompts": 100,
    "JailbreakingUnSafeResponses": 3,
    "JailbreakingSafeResponses": 97,
    "Latency": "~0.5-1s",
    "GPQA": "75.40%",
    "SWE-Bench-Verified": "72.7%",
    "Multimodal": "Yes",
    "Reasoning": "Yes",
    "Web Access": "Yes",
    "Fine-tunable": "No"
  }
]