[
  {
    "Model": "Claude 3 Haiku",
    "Description": "Claude 3 Haiku is Anthropic's fastest and most affordable model with 20B parameters, designed for quick responses and light tasks. With strong safety features and 22.9% mathematical reasoning capability, it offers reliable performance for everyday AI applications at an accessible $0.25 per million input tokens.",
    "Meta-description": "Claude 3 Haiku by Anthropic - Fast, affordable 20B parameter AI model ideal for quick responses and light tasks. Strong safety features with 22.9% math capability at $0.25/M tokens.",
    "OperationalRank": "#21",
    "SafetyRank": "N/A",
    "Org.": "Anthropic",
    "Size": "20B Parameters",
    "Released": "07-Mar-24",
    "CodeLMArena": "1184",
    "MathLiveBench": "22.90%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.25 ",
    "Output Cost/M": "$1.25 ",
    "CutoffKnowledge": "2023-08-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A"
  },
  {
    "Model": "Claude 3 Opus",
    "Description": "Claude 3 Opus represents Anthropic's most powerful model with 2T parameters, designed for complex reasoning and advanced analysis. Despite ranking #76 operationally, it delivers exceptional performance on sophisticated tasks with 43.4% mathematical reasoning and premium capabilities for enterprise applications.",
    "Meta-description": "Claude 3 Opus by Anthropic - Flagship 2T parameter AI model for complex reasoning and advanced analysis. Premium enterprise capabilities with 43.4% math performance at $15/M input tokens.",
    "OperationalRank": "#76",
    "SafetyRank": "N/A",
    "Org.": "Anthropic",
    "Size": "2T Parameters",
    "Released": "04-Mar-24",
    "CodeLMArena": "1236",
    "MathLiveBench": "43.40%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$15 ",
    "Output Cost/M": "$75 ",
    "CutoffKnowledge": "2023-08-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A"
  },
  {
    "Model": "Claude 3.5 Haiku",
    "Description": "Claude 3.5 Haiku offers enhanced performance with 20B parameters and updated training, achieving 35.5% mathematical reasoning and 28% coding capabilities. Released in October 2024 with improved efficiency at $1 per million input tokens, it provides excellent value for balanced AI tasks.",
    "Meta-description": "Claude 3.5 Haiku by Anthropic - Enhanced 20B parameter model with 35.5% math and 28% coding performance. Excellent value at $1/M tokens for balanced AI applications.",
    "OperationalRank": "#26",
    "SafetyRank": "N/A",
    "Org.": "Anthropic",
    "Size": "20B Parameters",
    "Released": "22-Oct-24",
    "CodeLMArena": "1263",
    "MathLiveBench": "35.50%",
    "CodeLiveBench": "28.00%",
    "Input Cost/M": "$1 ",
    "Output Cost/M": "$5 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A"
  },
  {
    "Model": "Claude 3.5 Sonnet",
    "Description": "Claude 3.5 Sonnet delivers strong performance with 70B parameters, achieving 51.3% mathematical reasoning and 32.3% coding capabilities. With a 1313 CodeLMArena score and 200K token context, it provides balanced excellence for professional applications at competitive pricing.",
    "Meta-description": "Claude 3.5 Sonnet by Anthropic - Powerful 70B parameter model with 51.3% math and 32.3% coding performance. Professional-grade AI with 1313 Arena score and 200K context at $3/M tokens.",
    "OperationalRank": "#34",
    "SafetyRank": "N/A",
    "Org.": "Anthropic",
    "Size": "70B Parameters",
    "Released": "22-Oct-24",
    "CodeLMArena": "1313",
    "MathLiveBench": "51.30%",
    "CodeLiveBench": "32.30%",
    "Input Cost/M": "$3 ",
    "Output Cost/M": "$15 ",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A"
  },
  {
    "Model": "Claude 3.7 Sonnet",
    "Description": "Claude 3.7 Sonnet sets the gold standard for AI safety with #1 safety ranking, achieving 100% safe responses and perfect jailbreaking resistance. With 70B parameters, 63.3% mathematical reasoning, and exceptional security features, it represents the safest production AI model available.",
    "Meta-description": "Claude 3.7 Sonnet by Anthropic - #1 safest AI model with 100% safe responses and perfect security. 70B parameters with 63.3% math performance and industry-leading safety at $3/M tokens.",
    "OperationalRank": "#31",
    "SafetyRank": "#1",
    "Org.": "Anthropic",
    "Size": "70B Parameters",
    "Released": "24-Feb-25",
    "CodeLMArena": "1326",
    "MathLiveBench": "63.30%",
    "CodeLiveBench": "32.40%",
    "Input Cost/M": "$3 ",
    "Output Cost/M": "$15 ",
    "CutoffKnowledge": "2024-10-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "100%",
    "UnsafeResponses": "0%",
    "JailbreakingResistance": "100%"
  },
  {
    "Model": "Claude 3.7 Sonnet Thinking",
    "OperationalRank": "#30",
    "SafetyRank": "N/A",
    "Org.": "Anthropic",
    "Size": "70B Parameters",
    "Released": "24-Feb-25",
    "CodeLMArena": "1333",
    "MathLiveBench": "77.50%",
    "CodeLiveBench": "44.70%",
    "Input Cost/M": "$3 ",
    "Output Cost/M": "$15 ",
    "CutoffKnowledge": "2024-10-01",
    "ContextLength": "200,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Claude 3.7 Sonnet Thinking incorporates advanced reasoning capabilities with explicit thinking processes. Featuring 70B parameters and exceptional mathematical performance (77.5% MathLiveBench), this model excels at complex problem-solving, step-by-step analysis, and transparent reasoning for research and educational applications.",
    "Meta-description": "Claude 3.7 Sonnet Thinking by Anthropic - Advanced 70B parameter model with transparent reasoning. Exceptional math performance (77.5%) and step-by-step problem-solving capabilities."
  },
  {
    "Model": "Codestral 25.01",
    "OperationalRank": "#50",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "-",
    "Released": "14-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": null,
    "ContextLength": "256,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Codestral 25.01 is Mistral's latest specialized coding model, designed specifically for software development tasks. With an extended 256K token context window, it handles large codebases and complex programming projects efficiently, making it ideal for developers and software engineering teams.",
    "Meta-description": "Codestral 25.01 by Mistral - Specialized coding AI model with 256K context window. Perfect for software development, large codebase analysis, and programming assistance."
  },
  {
    "Model": "DeepSeek 2.5",
    "OperationalRank": "#9",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "236B Parameters",
    "Released": "12-Sep-24",
    "CodeLMArena": "1255",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.13 ",
    "Output Cost/M": "$0.38 ",
    "CutoffKnowledge": "2023-11-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "DeepSeek 2.5 delivers impressive performance with 236B parameters at an exceptional value proposition. Ranked #9 operationally, it offers strong coding capabilities and cost-effective pricing, making it an attractive option for businesses seeking high performance without premium costs.",
    "Meta-description": "DeepSeek 2.5 - High-performance 236B parameter AI model ranked #9 globally. Cost-effective solution for coding, analysis, and business applications with excellent value."
  },
  {
    "Model": "DeepSeek Coder 2",
    "OperationalRank": "#10",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "236B Parameters",
    "Released": "22-Jul-24",
    "CodeLMArena": "1226",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.14 ",
    "Output Cost/M": "$0.28 ",
    "CutoffKnowledge": "2023-11-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "DeepSeek Coder 2 is a specialized programming model with 236B parameters, optimized for software development tasks. It provides excellent coding assistance at competitive pricing, making it ideal for developers, coding bootcamps, and software companies seeking reliable programming AI support.",
    "Meta-description": "DeepSeek Coder 2 - Specialized 236B parameter coding AI model. Excellent programming assistance at competitive prices. Perfect for developers and software development teams."
  },
  {
    "Model": "DeepSeek R1",
    "Description": "DeepSeek R1 represents a breakthrough in reasoning AI with 671B parameters and exceptional mathematical performance. Achieving 79.5% on MathLiveBench and 48.5% on CodeLiveBench, this open-source model ranks #5 in safety with 89% safe responses and offers advanced reasoning capabilities at competitive pricing.",
    "Meta-description": "DeepSeek R1 - Advanced 671B parameter open-source AI model with 79.5% math and 48.5% coding performance. #5 safety ranking with 89% safe responses at $0.55/M tokens.",
    "OperationalRank": "#14",
    "SafetyRank": "#5",
    "Org.": "DeepSeek",
    "Size": "671B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "79.50%",
    "CodeLiveBench": "48.50%",
    "Input Cost/M": "$0.55 ",
    "Output Cost/M": "$2.19 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "89%",
    "UnsafeResponses": "11%",
    "JailbreakingResistance": "32%"
  },
  {
    "Model": "DeepSeek V3",
    "OperationalRank": "#13",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "685B Parameters",
    "Released": "24-Mar-25",
    "CodeLMArena": "-",
    "MathLiveBench": "73.50%",
    "CodeLiveBench": "40.50%",
    "Input Cost/M": "$0.27 ",
    "Output Cost/M": "$1.10 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "DeepSeek V3 is a massive 685B parameter open-source model that delivers exceptional performance in mathematical reasoning (73.5% MathLiveBench) and coding tasks (40.5% CodeLiveBench). As an open-source solution, it provides enterprise-level capabilities with transparency and customization options.",
    "Meta-description": "DeepSeek V3 - Massive 685B parameter open-source AI model with excellent math (73.5%) and coding (40.5%) performance. Enterprise capabilities with open-source transparency."
  },
  {
    "Model": "DeepSeek V3",
    "OperationalRank": "#13",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "671B Parameters",
    "Released": "26-Dec-24",
    "CodeLMArena": "1279",
    "MathLiveBench": "60.50%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.07 ",
    "Output Cost/M": "$1.10 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "DeepSeek V3 is a massive 685B parameter open-source model that delivers exceptional performance in mathematical reasoning (73.5% MathLiveBench) and coding tasks (40.5% CodeLiveBench). As an open-source solution, it provides enterprise-level capabilities with transparency and customization options.",
    "Meta-description": "DeepSeek V3 - Massive 685B parameter open-source AI model with excellent math (73.5%) and coding (40.5%) performance. Enterprise capabilities with open-source transparency."
  },
  {
    "Model": "Gemini 1.5 Flash",
    "OperationalRank": "#2",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "8B Parameters",
    "Released": "24-Sep-24",
    "CodeLMArena": "1167",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.04 ",
    "Output Cost/M": "$0.15 ",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini 1.5 Flash is Google's speed-optimized model with 8B parameters, designed for rapid response and high throughput applications. Ranked #2 operationally with ultra-low pricing and massive 1M token context, it's perfect for real-time applications, chatbots, and high-volume processing tasks.",
    "Meta-description": "Gemini 1.5 Flash by Google - Ultra-fast 8B parameter AI model ranked #2 globally. 1M token context with ultra-low pricing. Perfect for real-time applications and chatbots."
  },
  {
    "Model": "Gemini 2.0 Flash",
    "OperationalRank": "#3",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "05-Feb-25",
    "CodeLMArena": "1271",
    "MathLiveBench": "65.60%",
    "CodeLiveBench": "26.20%",
    "Input Cost/M": "$0.10 ",
    "Output Cost/M": "$0.40 ",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini 2.0 Flash represents Google's next-generation speed model with enhanced capabilities. Ranked #3 operationally, it delivers excellent mathematical reasoning (65.6% MathLiveBench) and coding performance (26.2% CodeLiveBench) while maintaining rapid response times and competitive pricing.",
    "Meta-description": "Gemini 2.0 Flash by Google - Next-gen speed model ranked #3 with excellent math (65.6%) and coding abilities. Enhanced performance with rapid response times."
  },
  {
    "Model": "Gemini 2.0 Flash-Lite",
    "OperationalRank": "#5",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "05-Feb-25",
    "CodeLMArena": "1246",
    "MathLiveBench": "55.50%",
    "CodeLiveBench": "23.40%",
    "Input Cost/M": "$0.08 ",
    "Output Cost/M": "$0.30 ",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini 2.0 Flash-Lite offers a streamlined version of Google's advanced model, balancing performance with efficiency. With strong mathematical capabilities (55.5% MathLiveBench) and cost-effective pricing, it's ideal for applications requiring good performance without premium costs.",
    "Meta-description": "Gemini 2.0 Flash-Lite by Google - Streamlined AI model with strong math performance (55.5%) and cost-effective pricing. Balanced performance for budget-conscious applications."
  },
  {
    "Model": "Gemini 2.0 Pro",
    "OperationalRank": "#18",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "05-Feb-25",
    "CodeLMArena": "1298",
    "MathLiveBench": "71.00%",
    "CodeLiveBench": "35.30%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "2M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini 2.0 Pro is Google's flagship professional model with excellent mathematical reasoning (71% MathLiveBench) and superior coding capabilities (35.3% CodeLiveBench). Featuring a massive 2M token context window, it's designed for complex enterprise applications requiring extended context understanding.",
    "Meta-description": "Gemini 2.0 Pro by Google - Flagship professional AI with excellent math (71%) and coding (35.3%) performance. 2M token context for complex enterprise applications."
  },
  {
    "Model": "Gemini 2.5 Flash",
    "OperationalRank": "#4",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "17-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "58.40%",
    "Input Cost/M": "$0.15 ",
    "Output Cost/M": "$0.60 ",
    "CutoffKnowledge": "2025-01-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini 2.5 Flash represents Google's latest speed innovation with exceptional coding performance (58.4% CodeLiveBench) and current knowledge cutoff. This cutting-edge model combines rapid response times with advanced capabilities, making it ideal for modern development and real-time applications.",
    "Meta-description": "Gemini 2.5 Flash by Google - Latest speed model with exceptional coding performance (58.4%). Current knowledge and rapid response for modern development applications."
  },
  {
    "Model": "Gemini 2.5 Pro",
    "OperationalRank": "#6",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "25-Mar-25",
    "CodeLMArena": "1352",
    "MathLiveBench": "90.20%",
    "CodeLiveBench": "58.10%",
    "Input Cost/M": "$1.25 ",
    "Output Cost/M": "$10 ",
    "CutoffKnowledge": "2025-01-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini 2.5 Pro sets new standards with exceptional mathematical reasoning (90.2% MathLiveBench) and superior coding performance (58.1% CodeLiveBench). Ranked #6 globally, this flagship model delivers state-of-the-art performance across all domains with current knowledge and enterprise-grade capabilities.",
    "Meta-description": "Gemini 2.5 Pro by Google - State-of-the-art AI ranked #6 with exceptional math (90.2%) and coding (58.1%) performance. Enterprise-grade capabilities with current knowledge."
  },
  {
    "Model": "Gemini Exp 1114",
    "OperationalRank": "#43",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "14-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "54.90%",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "32,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini Exp 1114 is Google's experimental model showcasing advanced research capabilities with strong mathematical performance (54.9% MathLiveBench). As an experimental release, it provides early access to cutting-edge AI research and innovative approaches to language understanding.",
    "Meta-description": "Gemini Exp 1114 by Google - Experimental AI model with advanced research capabilities and strong math performance (54.9%). Early access to cutting-edge AI innovation."
  },
  {
    "Model": "Gemini Exp 1121",
    "OperationalRank": "#37",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "21-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "62.70%",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "32,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini Exp 1121 builds upon Google's experimental framework with enhanced mathematical reasoning (62.7% MathLiveBench). This research model explores advanced AI capabilities and serves as a testbed for innovative features that may appear in future production releases.",
    "Meta-description": "Gemini Exp 1121 by Google - Enhanced experimental AI model with improved math reasoning (62.7%). Research testbed for future AI innovations and advanced capabilities."
  },
  {
    "Model": "Gemini Exp 1206",
    "OperationalRank": "#20",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "-",
    "Released": "06-Dec-24",
    "CodeLMArena": "-",
    "MathLiveBench": "70.00%",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "2M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemini Exp 1206 represents Google's latest experimental advancement with strong mathematical performance (70% MathLiveBench) and an impressive 2M token context window. This research model pushes the boundaries of language understanding and context processing for next-generation applications.",
    "Meta-description": "Gemini Exp 1206 by Google - Latest experimental AI with strong math performance (70%) and 2M token context. Pushing boundaries of language understanding and context processing."
  },
  {
    "Model": "Gemma 1 2B",
    "OperationalRank": "#49",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "2B Parameters",
    "Released": "21-Feb-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "22.00%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2023-07-01",
    "ContextLength": "8,192 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 1 2B is Google's compact open-source model designed for edge computing and resource-constrained environments. With 2B parameters and coding capabilities (22% CodeLiveBench), it enables on-device AI applications while maintaining Google's quality standards in a lightweight package.",
    "Meta-description": "Gemma 1 2B by Google - Compact 2B parameter open-source model for edge computing. Lightweight AI with coding capabilities for resource-constrained environments."
  },
  {
    "Model": "Gemma 1 7B",
    "OperationalRank": "#48",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "7B Parameters",
    "Released": "21-Feb-24",
    "CodeLMArena": "-",
    "MathLiveBench": "51.80%",
    "CodeLiveBench": "32.30%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2023-07-01",
    "ContextLength": "8,192 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 1 7B offers a balanced approach with 7B parameters, delivering solid mathematical reasoning (51.8% MathLiveBench) and coding performance (32.3% CodeLiveBench). As an open-source model, it provides enterprise-quality capabilities with transparency and customization flexibility.",
    "Meta-description": "Gemma 1 7B by Google - Balanced 7B parameter open-source model with solid math (51.8%) and coding (32.3%) performance. Enterprise-quality with customization flexibility."
  },
  {
    "Model": "Gemma 2 27B",
    "OperationalRank": "#35",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "27B Parameters",
    "Released": "27-Jun-24",
    "CodeLMArena": "1218",
    "MathLiveBench": "74.00%",
    "CodeLiveBench": "51.80%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "8,192 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 2 27B represents Google's powerful open-source offering with 27B parameters, achieving excellent mathematical reasoning (74% MathLiveBench) and superior coding capabilities (51.8% CodeLiveBench). It combines large-scale performance with open-source accessibility for research and enterprise applications.",
    "Meta-description": "Gemma 2 27B by Google - Powerful 27B parameter open-source model with excellent math (74%) and coding (51.8%) performance. Large-scale capabilities with open-source accessibility."
  },
  {
    "Model": "Gemma 2 2B",
    "OperationalRank": "#51",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "2B Parameters",
    "Released": "31-Jul-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "20.10%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "8,192 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 2 2B is Google's ultra-efficient model designed for mobile and edge applications. With 2B parameters and basic coding capabilities (20.1% CodeLiveBench), it enables AI integration in resource-limited environments while maintaining Google's quality and safety standards.",
    "Meta-description": "Gemma 2 2B by Google - Ultra-efficient 2B parameter model for mobile and edge applications. AI integration for resource-limited environments with quality standards."
  },
  {
    "Model": "Gemma 2 9B",
    "OperationalRank": "#39",
    "SafetyRank": "#7",
    "Org.": "Google",
    "Size": "9B Parameters",
    "Released": "27-Jun-24",
    "CodeLMArena": "1187",
    "MathLiveBench": "68.60%",
    "CodeLiveBench": "40.20%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "8,192 tokens",
    "License": "Open Source",
    "SafeResponses": "98%",
    "UnsafeResponses": "1%",
    "JailbreakingResistance": "2%",
    "Description": "Gemma 2 9B excels with strong mathematical reasoning (68.6% MathLiveBench) and excellent safety measures, ranking #7 in safety with 98% safe responses. This 9B parameter open-source model is ideal for applications requiring both performance and responsible AI deployment.",
    "Meta-description": "Gemma 2 9B by Google - Excellent 9B parameter model with strong math (68.6%) and #7 safety ranking (98% safe). Perfect balance of performance and responsible AI."
  },
  {
    "Model": "Gemma 3 12B",
    "OperationalRank": "#56",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "12B Parameters",
    "Released": "10-Mar-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 3 12B represents Google's latest generation open-source model with 12B parameters and an extended 128K token context window. With current knowledge cutoff (2024-12-01), it provides modern capabilities for research, development, and enterprise applications requiring recent information.",
    "Meta-description": "Gemma 3 12B by Google - Latest generation 12B parameter open-source model with 128K context and current knowledge (Dec 2024). Modern capabilities for research and enterprise."
  },
  {
    "Model": "Gemma 3 1B",
    "OperationalRank": "#54",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "1B Parameters",
    "Released": "10-Mar-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 3 1B is Google's most compact third-generation model with 1B parameters, designed for ultra-lightweight applications. With 128K context window and current knowledge, it enables AI functionality in extremely resource-constrained environments without sacrificing modern capabilities.",
    "Meta-description": "Gemma 3 1B by Google - Ultra-compact 1B parameter model with 128K context and current knowledge. AI functionality for extremely resource-constrained environments."
  },
  {
    "Model": "Gemma 3 27B",
    "OperationalRank": "#29",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "27B Parameters",
    "Released": "10-Mar-25",
    "CodeLMArena": "1218",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 3 27B delivers high-performance capabilities with 27B parameters and an enhanced 128K token context window. This latest-generation open-source model provides enterprise-level performance with current knowledge and extended context understanding for complex applications.",
    "Meta-description": "Gemma 3 27B by Google - High-performance 27B parameter open-source model with 128K context and current knowledge. Enterprise-level capabilities for complex applications."
  },
  {
    "Model": "Gemma 3 4B",
    "OperationalRank": "#55",
    "SafetyRank": "N/A",
    "Org.": "Google",
    "Size": "4B Parameters",
    "Released": "10-Mar-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Gemma 3 4B is Google's latest-generation model with 4B parameters, designed for ultra-lightweight applications. With 128K context window and current knowledge, it enables AI functionality in extremely resource-constrained environments without sacrificing modern capabilities.",
    "Meta-description": "Gemma 3 4B by Google - Ultra-compact 4B parameter model with 128K context and current knowledge. AI functionality for extremely resource-constrained environments."
  },
  {
    "Model": "GPT 4.1",
    "OperationalRank": "#7",
    "SafetyRank": "#3",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "14-Apr-25",
    "CodeLMArena": "1385",
    "MathLiveBench": "72.00%",
    "CodeLiveBench": "54.60%",
    "Input Cost/M": "$2 ",
    "Output Cost/M": "$8 ",
    "CutoffKnowledge": "2024-06-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "97%",
    "UnsafeResponses": "2%",
    "JailbreakingResistance": "34%",
    "Description": "GPT 4.1 represents OpenAI's latest flagship model with exceptional performance across all domains. Ranked #7 operationally and #3 in safety, it delivers outstanding coding (54.6% CodeLiveBench) and mathematical reasoning (72% MathLiveBench) while maintaining strong safety measures with 97% safe responses.",
    "Meta-description": "GPT 4.1 by OpenAI - Latest flagship AI ranked #7 globally with excellent coding (54.6%) and math (72%) performance. #3 safety ranking with 97% safe responses for enterprise use.",
    "providers": {
      "OpenAI": {
        "model_id": "gpt-4.1-2025-04-14",
        "price_per_input_token": 0.000002,
        "price_per_output_token": 0.000008,
        "price_per_million_input_tokens": "$2.00",
        "price_per_million_output_tokens": "$8.00",
        "throughput": 100,
        "latency": 10,
        "updated_at": "2025-04-14",
        "website": "https://openai.com",
        "api_endpoint": "https://api.openai.com/v1/chat/completions"
      }
    }
  },
  {
    "Model": "GPT 4.1 mini",
    "OperationalRank": "#8",
    "SafetyRank": "N/A",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "14-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "47.60%",
    "Input Cost/M": "$0.40 ",
    "Output Cost/M": "$1.60 ",
    "CutoffKnowledge": "2024-06-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "GPT 4.1 mini offers OpenAI's advanced capabilities in a more cost-effective package. Ranked #8 operationally with strong coding performance (47.6% CodeLiveBench) and 1M token context, it provides excellent value for applications requiring GPT-4 level intelligence at reduced costs.",
    "Meta-description": "GPT 4.1 mini by OpenAI - Cost-effective AI ranked #8 with strong coding performance (47.6%) and 1M context. GPT-4 level intelligence at reduced costs for value-conscious applications.",
    "providers": {
      "OpenAI": {
        "model_id": "gpt-4.1-mini-2025-04-14",
        "price_per_input_token": 4e-7,
        "price_per_output_token": 0.0000016,
        "price_per_million_input_tokens": "$0.40",
        "price_per_million_output_tokens": "$1.60",
        "throughput": 150,
        "latency": 5,
        "updated_at": "2025-04-14",
        "website": "https://openai.com",
        "api_endpoint": "https://api.openai.com/v1/chat/completions"
      }
    }
  },
  {
    "Model": "GPT 4.1 nano",
    "OperationalRank": "#11",
    "SafetyRank": "#4",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "14-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "25.30%",
    "Input Cost/M": "$0.10 ",
    "Output Cost/M": "$0.40 ",
    "CutoffKnowledge": "2024-06-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "95%",
    "UnsafeResponses": "4%",
    "JailbreakingResistance": "34%",
    "Description": "GPT 4.1 nano is OpenAI's ultra-efficient model designed for high-volume applications. Ranked #11 operationally and #4 in safety with 95% safe responses, it provides reliable AI capabilities with excellent cost efficiency and safety measures for production deployments.",
    "Meta-description": "GPT 4.1 nano by OpenAI - Ultra-efficient AI ranked #11 with #4 safety ranking (95% safe). Excellent cost efficiency and reliability for high-volume production deployments.",
    "providers": {
      "OpenAI": {
        "model_id": "gpt-4.1-nano-2025-04-14",
        "price_per_input_token": 1e-7,
        "price_per_output_token": 4e-7,
        "price_per_million_input_tokens": "$0.10",
        "price_per_million_output_tokens": "$0.40",
        "throughput": 200,
        "latency": 2,
        "updated_at": "2025-04-14",
        "website": "https://openai.com",
        "api_endpoint": "https://api.openai.com/v1/chat/completions"
      }
    }
  },
  {
    "Model": "GPT 4.5",
    "OperationalRank": "#77",
    "SafetyRank": "#2",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "27-Feb-25",
    "CodeLMArena": "1362",
    "MathLiveBench": "69.30%",
    "CodeLiveBench": "76.10%",
    "Input Cost/M": "$75 ",
    "Output Cost/M": "$150 ",
    "CutoffKnowledge": null,
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "99.60%",
    "UnsafeResponses": "0.40%",
    "JailbreakingResistance": "97.30%",
    "Description": "GPT 4.5 represents OpenAI's most advanced and secure model, achieving #2 safety ranking with exceptional 99.6% safe responses and 97.3% jailbreaking resistance. With superior coding performance (76.1% CodeLiveBench), it's designed for the most demanding enterprise applications requiring maximum safety and performance.",
    "Meta-description": "GPT 4.5 by OpenAI - Most advanced and secure AI with #2 safety ranking (99.6% safe responses). Superior coding (76.1%) and maximum security for enterprise applications.",
    "providers": {
      "OpenAI": {
        "model_id": "gpt-4.5",
        "price_per_input_token": 0.000075,
        "price_per_output_token": 0.00015,
        "price_per_million_input_tokens": "$75.00",
        "price_per_million_output_tokens": "$150.00",
        "throughput": 50,
        "latency": 20,
        "updated_at": "2025-03-04",
        "website": "https://openai.com",
        "api_endpoint": "https://api.openai.com/v1/chat/completions"
      }
    }
  },
  {
    "Model": "GPT 4o",
    "OperationalRank": "#28",
    "SafetyRank": "N/A",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "26-Mar-25",
    "CodeLMArena": "1385",
    "MathLiveBench": "-",
    "CodeLiveBench": "77.50%",
    "Input Cost/M": "$5 ",
    "Output Cost/M": "$15 ",
    "CutoffKnowledge": "2023-10-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "GPT 4o delivers exceptional coding performance with 77.5% CodeLiveBench, making it one of the most capable programming assistants available. Ranked #28 operationally with multimodal capabilities and 128K context, it excels at complex software development and technical tasks.",
    "Meta-description": "GPT 4o by OpenAI - Exceptional coding AI with 77.5% CodeLiveBench performance. Multimodal capabilities and 128K context for complex software development and technical tasks.",
    "providers": {
      "Azure": {
        "model_id": "gpt-4o-2024-08-06",
        "price_per_input_token": 0.0000025,
        "price_per_output_token": 0.00001,
        "price_per_million_input_tokens": "$2.50",
        "price_per_million_output_tokens": "$10.00",
        "throughput": 99,
        "latency": 0.53,
        "updated_at": "2024-09-09",
        "website": "https://azure.microsoft.com",
        "api_endpoint": "https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions"
      },
      "OpenAI": {
        "model_id": "gpt-4o-2024-08-06",
        "price_per_input_token": 0.0000025,
        "price_per_output_token": 0.00001,
        "price_per_million_input_tokens": "$2.50",
        "price_per_million_output_tokens": "$10.00",
        "throughput": 132,
        "latency": 0.5,
        "updated_at": "2024-09-09",
        "website": "https://openai.com",
        "api_endpoint": "https://api.openai.com/v1/chat/completions"
      }
    }
  },
  {
    "Model": "GPT 4o mini",
    "OperationalRank": "#22",
    "SafetyRank": "N/A",
    "Org.": "OpenAI",
    "Size": "-",
    "Released": "18-Jul-24",
    "CodeLMArena": "1245",
    "MathLiveBench": "35.60%",
    "CodeLiveBench": "25.50%",
    "Input Cost/M": "$0.15 ",
    "Output Cost/M": "$0.60 ",
    "CutoffKnowledge": "2023-10-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "GPT 4o mini provides OpenAI's multimodal capabilities in a cost-effective package. Ranked #22 operationally with solid mathematical reasoning (35.6% MathLiveBench) and coding abilities (25.5% CodeLiveBench), it offers an excellent balance of performance and affordability for diverse applications.",
    "Meta-description": "GPT 4o mini by OpenAI - Cost-effective multimodal AI ranked #22 with solid math (35.6%) and coding (25.5%) performance. Excellent balance of capabilities and affordability.",
    "providers": {
      "Azure": {
        "model_id": "gpt-4o-mini-2024-07-18",
        "price_per_input_token": 1.5e-7,
        "price_per_output_token": 6e-7,
        "price_per_million_input_tokens": "$0.15",
        "price_per_million_output_tokens": "$0.60",
        "throughput": 92,
        "latency": 0.52,
        "updated_at": "2024-09-09",
        "website": "https://azure.microsoft.com",
        "api_endpoint": "https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions"
      },
      "OpenAI": {
        "model_id": "gpt-4o-mini",
        "price_per_input_token": 1.5e-7,
        "price_per_output_token": 6e-7,
        "price_per_million_input_tokens": "$0.15",
        "price_per_million_output_tokens": "$0.60",
        "throughput": 100,
        "latency": 0.5,
        "updated_at": "2024-07-18",
        "website": "https://openai.com",
        "api_endpoint": "https://api.openai.com/v1/chat/completions"
      }
    }
  },
  {
    "Model": "Grok-3",
    "OperationalRank": "#70",
    "SafetyRank": "#11",
    "Org.": "xAI",
    "Size": "300B Parameters",
    "Released": "01-May-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": null,
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "2.70%",
    "UnsafeResponses": "97.30%",
    "JailbreakingResistance": "2.70%",
    "Description": "Grok-3 is xAI's large-scale language model with 300B parameters, designed for unrestricted conversations and creative applications. Ranked #11 in safety with unique characteristics, it offers a different approach to AI interaction with minimal content filtering for specialized use cases.",
    "Meta-description": "Grok-3 by xAI - Large 300B parameter AI model with unrestricted conversation capabilities. Unique approach to AI interaction with minimal filtering for specialized applications."
  },
  {
    "Model": "Llama 3.1",
    "OperationalRank": "#23",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "70B Parameters",
    "Released": "23-Jul-24",
    "CodeLMArena": "1209",
    "MathLiveBench": "34.40%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$1 ",
    "Output Cost/M": "$3 ",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 3.1 is Meta's powerful open-source model with 70B parameters, offering strong coding capabilities (1209 CodeLMArena) and mathematical reasoning (34.4% MathLiveBench). With 128K context and competitive pricing, it provides enterprise-level performance with open-source flexibility.",
    "Meta-description": "Llama 3.1 by Meta - Powerful 70B parameter open-source AI with strong coding and math abilities. Enterprise performance with open-source flexibility and competitive pricing."
  },
  {
    "Model": "Llama 3.2",
    "OperationalRank": "#12",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "3B Parameters",
    "Released": "25-Sep-24",
    "CodeLMArena": "1048",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.08 ",
    "Output Cost/M": "$0.10 ",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 3.2 is Meta's compact yet efficient model with 3B parameters, designed for cost-effective AI applications. Ranked #12 operationally with ultra-low pricing and 128K context, it's perfect for applications requiring good performance at minimal cost.",
    "Meta-description": "Llama 3.2 by Meta - Compact 3B parameter model ranked #12 with ultra-low pricing. Cost-effective AI for applications requiring good performance at minimal cost."
  },
  {
    "Model": "Llama 3.2 (Vision)",
    "OperationalRank": "#38",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "90B Parameters",
    "Released": "25-Sep-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.90 ",
    "Output Cost/M": "$0.90 ",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 3.2 Vision extends Meta's capabilities with multimodal processing, featuring 90B parameters for both text and visual understanding. This open-source model enables applications requiring image analysis, visual reasoning, and multimodal AI interactions.",
    "Meta-description": "Llama 3.2 Vision by Meta - Multimodal 90B parameter open-source AI with text and visual understanding. Perfect for image analysis and visual reasoning applications."
  },
  {
    "Model": "Llama 3.3",
    "OperationalRank": "#19",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "70B Parameters",
    "Released": "06-Dec-24",
    "CodeLMArena": "1232",
    "MathLiveBench": "41.10%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.10 ",
    "Output Cost/M": "$0.40 ",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 3.3 represents Meta's enhanced 70B parameter model with improved mathematical reasoning (41.1% MathLiveBench) and coding capabilities. With ultra-competitive pricing and open-source accessibility, it offers excellent value for developers and organizations seeking reliable AI performance.",
    "Meta-description": "Llama 3.3 by Meta - Enhanced 70B parameter model with improved math (41.1%) and coding abilities. Ultra-competitive pricing with open-source accessibility."
  },
  {
    "Model": "Llama 4 Behemoth",
    "OperationalRank": "#58",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "2T Parameters",
    "Released": "05-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 4 Behemoth is Meta's massive 2T parameter open-source model, designed for the most demanding AI applications. With cutting-edge architecture and current knowledge, it represents the pinnacle of open-source AI capability for research and enterprise use.",
    "Meta-description": "Llama 4 Behemoth by Meta - Massive 2T parameter open-source AI model for demanding applications. Pinnacle of open-source AI capability for research and enterprise use."
  },
  {
    "Model": "Llama 4 Maverick",
    "OperationalRank": "#1",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "400B Parameters",
    "Released": "05-Apr-25",
    "CodeLMArena": "1265",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.19 ",
    "Output Cost/M": "$0.49 ",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "1M tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 4 Maverick achieves the #1 operational ranking with 400B parameters, representing Meta's most advanced open-source model. With exceptional performance and ultra-competitive pricing, it sets new standards for open-source AI accessibility and capability.",
    "Meta-description": "Llama 4 Maverick by Meta - #1 ranked 400B parameter open-source AI model. Most advanced open-source AI with exceptional performance and ultra-competitive pricing."
  },
  {
    "Model": "Llama 4 Maverick 17B 128e Instruct",
    "OperationalRank": "#33",
    "SafetyRank": "#9",
    "Org.": "Meta",
    "Size": "17B Parameters (400B total with MoE)",
    "Released": "05-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.20 ",
    "Output Cost/M": "$0.60 ",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "93%",
    "UnsafeResponses": "6%",
    "JailbreakingResistance": "1%",
    "Description": "Llama 4 Maverick 17B is Meta's efficient MoE model with 17B active parameters from a 400B total architecture. Ranked #9 in safety with 93% safe responses, it combines high performance with responsible AI deployment and cost efficiency.",
    "Meta-description": "Llama 4 Maverick 17B by Meta - Efficient MoE model with 17B active parameters and #9 safety ranking (93% safe). High performance with responsible AI deployment."
  },
  {
    "Model": "Llama 4 Scout",
    "OperationalRank": "#42",
    "SafetyRank": "N/A",
    "Org.": "Meta",
    "Size": "109B Parameters",
    "Released": "05-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "10M tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Llama 4 Scout features 109B parameters with an extraordinary 10M token context window, designed for applications requiring massive context understanding. This open-source model excels at processing large documents, codebases, and extended conversations.",
    "Meta-description": "Llama 4 Scout by Meta - 109B parameter model with extraordinary 10M token context window. Perfect for large document processing and extended conversations."
  },
  {
    "Model": "llama-3.1-8b-instant",
    "OperationalRank": "#64",
    "SafetyRank": "#8",
    "Org.": "Meta",
    "Size": "8B Parameters",
    "Released": "23-Jul-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "94%",
    "UnsafeResponses": "5%",
    "JailbreakingResistance": "1%",
    "Description": "Llama 3.1 8B Instant is Meta's optimized model for rapid response applications with 8B parameters. Ranked #8 in safety with 94% safe responses, it provides reliable AI capabilities with excellent safety measures for production deployments requiring speed.",
    "Meta-description": "Llama 3.1 8B Instant by Meta - Optimized 8B parameter model for rapid response with #8 safety ranking (94% safe). Reliable AI with excellent safety for speed-critical applications."
  },
  {
    "Model": "Llama-4-scout-17b-16e-instruct",
    "OperationalRank": "#52",
    "SafetyRank": "#10",
    "Org.": "Meta",
    "Size": "17B Parameters (MoE)",
    "Released": "05-Apr-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-08-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "91%",
    "UnsafeResponses": "8%",
    "JailbreakingResistance": "1%",
    "Description": "Llama 4 Scout 17B is Meta's specialized MoE instruction model with 17B parameters, designed for efficient task completion. Ranked #10 in safety with 91% safe responses, it balances performance with responsible AI deployment for instruction-following applications.",
    "Meta-description": "Llama 4 Scout 17B by Meta - Specialized MoE instruction model with #10 safety ranking (91% safe). Balanced performance with responsible AI for instruction-following tasks."
  },
  {
    "Model": "Mistral Large",
    "OperationalRank": "#25",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "123B Parameters",
    "Released": "18-Nov-24",
    "CodeLMArena": "1228",
    "MathLiveBench": "32.60%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$2 ",
    "Output Cost/M": "$6 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Mistral Large is a powerful 123B parameter model designed for complex reasoning and professional applications. With strong mathematical capabilities (43.7% MathLiveBench) and coding performance, it offers European AI excellence with competitive pricing for enterprise use.",
    "Meta-description": "Mistral Large - Powerful 123B parameter AI model with strong math (43.7%) and coding performance. European AI excellence with competitive pricing for enterprise applications."
  },
  {
    "Model": "Mistral Large",
    "OperationalRank": "#25",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "123B Parameters",
    "Released": "24-Jul-24",
    "CodeLMArena": "1244",
    "MathLiveBench": "43.70%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$2 ",
    "Output Cost/M": "$6 ",
    "CutoffKnowledge": "2024-07-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Mistral Large is a powerful 123B parameter model designed for complex reasoning and professional applications. With strong mathematical capabilities (43.7% MathLiveBench) and coding performance, it offers European AI excellence with competitive pricing for enterprise use.",
    "Meta-description": "Mistral Large - Powerful 123B parameter AI model with strong math (43.7%) and coding performance. European AI excellence with competitive pricing for enterprise applications."
  },
  {
    "Model": "Mistral Medium 3",
    "OperationalRank": "#36",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "-",
    "Released": "07-May-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.40 ",
    "Output Cost/M": "$2 ",
    "CutoffKnowledge": null,
    "ContextLength": "-",
    "License": "-",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Mistral Medium 3 offers balanced performance for mid-tier applications requiring reliable AI capabilities. With competitive pricing and European data sovereignty, it's ideal for businesses seeking dependable AI solutions without premium costs.",
    "Meta-description": "Mistral Medium 3 - Balanced AI model for mid-tier applications with competitive pricing. European data sovereignty and dependable performance for business applications."
  },
  {
    "Model": "Mistral Nemo",
    "OperationalRank": "#32",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "12B Parameters",
    "Released": "24-Jul-24",
    "CodeLMArena": "-",
    "MathLiveBench": "16.90%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.15 ",
    "Output Cost/M": "$0.15 ",
    "CutoffKnowledge": "2024-04-01",
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Mistral Nemo is a compact 12B parameter model optimized for efficiency and cost-effectiveness. With mathematical reasoning capabilities (16.9% MathLiveBench) and 128K context, it provides reliable AI performance for applications requiring good capabilities at competitive prices.",
    "Meta-description": "Mistral Nemo - Compact 12B parameter model optimized for efficiency with math capabilities (16.9%). Reliable AI performance at competitive prices for cost-conscious applications."
  },
  {
    "Model": "Mistral Small 3",
    "OperationalRank": "#57",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "24B Parameters",
    "Released": "30-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": null,
    "ContextLength": "32,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Mistral Small 3 is a lightweight 24B parameter model designed for efficient AI applications. With compact context and European AI heritage, it provides reliable performance for applications requiring good capabilities without extensive resource requirements.",
    "Meta-description": "Mistral Small 3 - Lightweight 24B parameter model for efficient AI applications. European AI heritage with reliable performance for resource-conscious deployments."
  },
  {
    "Model": "Mistral Small 3.1",
    "OperationalRank": "#53",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "24B Parameters",
    "Released": "17-Mar-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": null,
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Mistral Small 3.1 enhances the compact model line with 24B parameters and extended 128K context. As an open-source offering, it provides European AI innovation with transparency and customization options for developers and researchers.",
    "Meta-description": "Mistral Small 3.1 - Enhanced 24B parameter open-source model with 128K context. European AI innovation with transparency and customization for developers."
  },
  {
    "Model": "Pixtral Large",
    "OperationalRank": "#47",
    "SafetyRank": "N/A",
    "Org.": "Mistral",
    "Size": "123B Parameters",
    "Released": "18-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$2 ",
    "Output Cost/M": "$6 ",
    "CutoffKnowledge": null,
    "ContextLength": "128,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Pixtral Large is Mistral's multimodal model with 123B parameters, combining text and visual understanding capabilities. This advanced model enables applications requiring image analysis, visual reasoning, and multimodal AI interactions with European AI standards.",
    "Meta-description": "Pixtral Large by Mistral - Multimodal 123B parameter AI with text and visual understanding. Advanced image analysis and visual reasoning with European AI standards."
  },
  {
    "Model": "Qwen 2.5",
    "OperationalRank": "#15",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "7B Parameters",
    "Released": "19-Sep-24",
    "CodeLMArena": "-",
    "MathLiveBench": "38.20%",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 (7B) is Alibaba's efficient model with strong mathematical reasoning (38.2% MathLiveBench) and current knowledge. With 128K context and open-source accessibility, it provides excellent performance for applications requiring modern AI capabilities at scale.",
    "Meta-description": "Qwen 2.5 7B by Alibaba - Efficient model with strong math reasoning (38.2%) and current knowledge. Open-source accessibility with excellent performance for modern AI applications."
  },
  {
    "Model": "Qwen 2.5",
    "OperationalRank": "#15",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "72B Parameters",
    "Released": "19-Sep-24",
    "CodeLMArena": "1247",
    "MathLiveBench": "52.40%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.38 ",
    "Output Cost/M": "$0.57 ",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 (7B) is Alibaba's efficient model with strong mathematical reasoning (38.2% MathLiveBench) and current knowledge. With 128K context and open-source accessibility, it provides excellent performance for applications requiring modern AI capabilities at scale.",
    "Meta-description": "Qwen 2.5 7B by Alibaba - Efficient model with strong math reasoning (38.2%) and current knowledge. Open-source accessibility with excellent performance for modern AI applications."
  },
  {
    "Model": "Qwen 2.5",
    "OperationalRank": "#15",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "32B Parameters",
    "Released": "19-Sep-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 (7B) is Alibaba's efficient model with strong mathematical reasoning (38.2% MathLiveBench) and current knowledge. With 128K context and open-source accessibility, it provides excellent performance for applications requiring modern AI capabilities at scale.",
    "Meta-description": "Qwen 2.5 7B by Alibaba - Efficient model with strong math reasoning (38.2%) and current knowledge. Open-source accessibility with excellent performance for modern AI applications."
  },
  {
    "Model": "Qwen 2.5",
    "OperationalRank": "#15",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "14B Parameters",
    "Released": "19-Sep-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 (7B) is Alibaba's efficient model with strong mathematical reasoning (38.2% MathLiveBench) and current knowledge. With 128K context and open-source accessibility, it provides excellent performance for applications requiring modern AI capabilities at scale.",
    "Meta-description": "Qwen 2.5 7B by Alibaba - Efficient model with strong math reasoning (38.2%) and current knowledge. Open-source accessibility with excellent performance for modern AI applications."
  },
  {
    "Model": "Qwen 2.5",
    "OperationalRank": "#15",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "1.5B Parameters",
    "Released": "19-Sep-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "32,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 (7B) is Alibaba's efficient model with strong mathematical reasoning (38.2% MathLiveBench) and current knowledge. With 128K context and open-source accessibility, it provides excellent performance for applications requiring modern AI capabilities at scale.",
    "Meta-description": "Qwen 2.5 7B by Alibaba - Efficient model with strong math reasoning (38.2%) and current knowledge. Open-source accessibility with excellent performance for modern AI applications."
  },
  {
    "Model": "Qwen 2.5",
    "OperationalRank": "#15",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "3B Parameters",
    "Released": "19-Sep-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "32,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 (7B) is Alibaba's efficient model with strong mathematical reasoning (38.2% MathLiveBench) and current knowledge. With 128K context and open-source accessibility, it provides excellent performance for applications requiring modern AI capabilities at scale.",
    "Meta-description": "Qwen 2.5 7B by Alibaba - Efficient model with strong math reasoning (38.2%) and current knowledge. Open-source accessibility with excellent performance for modern AI applications."
  },
  {
    "Model": "Qwen 2.5 Coder",
    "OperationalRank": "#16",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "32B Parameters",
    "Released": "12-Nov-24",
    "CodeLMArena": "1227",
    "MathLiveBench": "46.00%",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.20 ",
    "Output Cost/M": "$0.20 ",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Coder (32B) is Alibaba's specialized programming model with strong mathematical reasoning (46% MathLiveBench) and coding capabilities. Designed specifically for software development, it provides excellent programming assistance with current knowledge and competitive pricing.",
    "Meta-description": "Qwen 2.5 Coder 32B by Alibaba - Specialized programming model with strong math (46%) and coding capabilities. Excellent programming assistance with current knowledge."
  },
  {
    "Model": "Qwen 2.5 Coder",
    "OperationalRank": "#16",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "14B Parameters",
    "Released": "12-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Coder (32B) is Alibaba's specialized programming model with strong mathematical reasoning (46% MathLiveBench) and coding capabilities. Designed specifically for software development, it provides excellent programming assistance with current knowledge and competitive pricing.",
    "Meta-description": "Qwen 2.5 Coder 32B by Alibaba - Specialized programming model with strong math (46%) and coding capabilities. Excellent programming assistance with current knowledge."
  },
  {
    "Model": "Qwen 2.5 Coder",
    "OperationalRank": "#16",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "7B Parameters",
    "Released": "12-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Coder (32B) is Alibaba's specialized programming model with strong mathematical reasoning (46% MathLiveBench) and coding capabilities. Designed specifically for software development, it provides excellent programming assistance with current knowledge and competitive pricing.",
    "Meta-description": "Qwen 2.5 Coder 32B by Alibaba - Specialized programming model with strong math (46%) and coding capabilities. Excellent programming assistance with current knowledge."
  },
  {
    "Model": "Qwen 2.5 Coder",
    "OperationalRank": "#16",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "3B Parameters",
    "Released": "12-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "32,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Coder (32B) is Alibaba's specialized programming model with strong mathematical reasoning (46% MathLiveBench) and coding capabilities. Designed specifically for software development, it provides excellent programming assistance with current knowledge and competitive pricing.",
    "Meta-description": "Qwen 2.5 Coder 32B by Alibaba - Specialized programming model with strong math (46%) and coding capabilities. Excellent programming assistance with current knowledge."
  },
  {
    "Model": "Qwen 2.5 Coder",
    "OperationalRank": "#16",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "1.5B Parameters",
    "Released": "12-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "$0.20 ",
    "Output Cost/M": "$0.60 ",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "32,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Coder (32B) is Alibaba's specialized programming model with strong mathematical reasoning (46% MathLiveBench) and coding capabilities. Designed specifically for software development, it provides excellent programming assistance with current knowledge and competitive pricing.",
    "Meta-description": "Qwen 2.5 Coder 32B by Alibaba - Specialized programming model with strong math (46%) and coding capabilities. Excellent programming assistance with current knowledge."
  },
  {
    "Model": "Qwen 2.5 Coder",
    "OperationalRank": "#16",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "0.5B Parameters",
    "Released": "12-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "32,000 tokens",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Coder (32B) is Alibaba's specialized programming model with strong mathematical reasoning (46% MathLiveBench) and coding capabilities. Designed specifically for software development, it provides excellent programming assistance with current knowledge and competitive pricing.",
    "Meta-description": "Qwen 2.5 Coder 32B by Alibaba - Specialized programming model with strong math (46%) and coding capabilities. Excellent programming assistance with current knowledge."
  },
  {
    "Model": "Qwen 2.5 Max",
    "OperationalRank": "#24",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "-",
    "Released": "28-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "33.80%",
    "Input Cost/M": "$1.60 ",
    "Output Cost/M": "$6.40 ",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "32,000 tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Max is Alibaba's flagship model offering exceptional performance with competitive pricing. With 33.8% coding capability and ultra-low cost structure, it provides enterprise-level AI capabilities with remarkable value, making advanced AI accessible for high-volume applications.",
    "Meta-description": "Qwen 2.5 Max by Alibaba - Flagship model with exceptional performance and ultra-low pricing. 33.8% coding capability making advanced AI accessible for high-volume applications."
  },
  {
    "Model": "Qwen 2.5 Turbo",
    "OperationalRank": "#45",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "-",
    "Released": "15-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "1M tokens",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5 Turbo delivers optimized speed and efficiency for real-time applications with 1M token context window. Designed for high-throughput scenarios, it combines Alibaba's AI expertise with rapid response times for applications requiring immediate AI processing.",
    "Meta-description": "Qwen 2.5 Turbo by Alibaba - Speed-optimized model with 1M token context for real-time applications. High-throughput AI processing with rapid response times."
  },
  {
    "Model": "Qwen 2.5VL",
    "OperationalRank": "#59",
    "SafetyRank": "N/A",
    "Org.": "Alibaba",
    "Size": "32B Parameters",
    "Released": "24-Mar-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": null,
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "Qwen 2.5VL is Alibaba's multimodal model with 32B parameters, combining vision and language understanding. This open-source model enables applications requiring visual analysis, image understanding, and multimodal AI interactions for research and commercial use.",
    "Meta-description": "Qwen 2.5VL by Alibaba - Multimodal 32B parameter open-source model with vision and language capabilities. Visual analysis and image understanding for research and commercial applications."
  },
  {
    "Model": "Qwen-qwq-32b",
    "OperationalRank": "#66",
    "SafetyRank": "#6",
    "Org.": "Alibaba",
    "Size": "32B Parameters",
    "Released": "12-Oct-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "128,000 tokens",
    "License": "Open Source",
    "SafeResponses": "94%",
    "UnsafeResponses": "5%",
    "JailbreakingResistance": "12%",
    "Description": "QwQ 32B is Alibaba's specialized reasoning model with 32B parameters, achieving #6 safety ranking with 94% safe responses. Designed for complex reasoning tasks, it combines strong analytical capabilities with responsible AI deployment for demanding applications.",
    "Meta-description": "QwQ 32B by Alibaba - Specialized 32B parameter reasoning model with #6 safety ranking (94% safe). Complex reasoning capabilities with responsible AI deployment."
  },
  {
    "Model": "R1 Distill Llama",
    "OperationalRank": "#44",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "70B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "46.60%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2023-12-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Distill Llama models are DeepSeek's knowledge distillation versions of their breakthrough R1 reasoning capabilities. Available in 70B and 8B variants, they provide efficient access to advanced reasoning features with open-source accessibility and strong coding performance.",
    "Meta-description": "R1 Distill Llama by DeepSeek - Efficient distillation of R1 reasoning capabilities in 70B and 8B variants. Open-source access to advanced reasoning with strong coding performance."
  },
  {
    "Model": "R1 Distill Llama",
    "OperationalRank": "#44",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "8B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-12-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Distill Llama models are DeepSeek's knowledge distillation versions of their breakthrough R1 reasoning capabilities. Available in 70B and 8B variants, they provide efficient access to advanced reasoning features with open-source accessibility and strong coding performance.",
    "Meta-description": "R1 Distill Llama by DeepSeek - Efficient distillation of R1 reasoning capabilities in 70B and 8B variants. Open-source access to advanced reasoning with strong coding performance."
  },
  {
    "Model": "R1 Distill Qwen",
    "OperationalRank": "#40",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "32B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "52.30%",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Distill Qwen models bring DeepSeek's advanced reasoning capabilities to Qwen architecture in multiple sizes (32B, 14B, 7B, 1.5B). These open-source models combine efficient reasoning with strong coding performance (52.3% CodeLiveBench) and current knowledge.",
    "Meta-description": "R1 Distill Qwen by DeepSeek - Advanced reasoning in Qwen architecture across multiple sizes. Open-source models with strong coding (52.3%) and current knowledge."
  },
  {
    "Model": "R1 Distill Qwen",
    "OperationalRank": "#40",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "14B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Distill Qwen models bring DeepSeek's advanced reasoning capabilities to Qwen architecture in multiple sizes (32B, 14B, 7B, 1.5B). These open-source models combine efficient reasoning with strong coding performance (52.3% CodeLiveBench) and current knowledge.",
    "Meta-description": "R1 Distill Qwen by DeepSeek - Advanced reasoning in Qwen architecture across multiple sizes. Open-source models with strong coding (52.3%) and current knowledge."
  },
  {
    "Model": "R1 Distill Qwen",
    "OperationalRank": "#40",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "7B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Distill Qwen models bring DeepSeek's advanced reasoning capabilities to Qwen architecture in multiple sizes (32B, 14B, 7B, 1.5B). These open-source models combine efficient reasoning with strong coding performance (52.3% CodeLiveBench) and current knowledge.",
    "Meta-description": "R1 Distill Qwen by DeepSeek - Advanced reasoning in Qwen architecture across multiple sizes. Open-source models with strong coding (52.3%) and current knowledge."
  },
  {
    "Model": "R1 Distill Qwen",
    "OperationalRank": "#40",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "1.5B Parameters",
    "Released": "20-Jan-25",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": "2024-09-01",
    "ContextLength": "-",
    "License": "Open Source",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Distill Qwen models bring DeepSeek's advanced reasoning capabilities to Qwen architecture in multiple sizes (32B, 14B, 7B, 1.5B). These open-source models combine efficient reasoning with strong coding performance (52.3% CodeLiveBench) and current knowledge.",
    "Meta-description": "R1 Distill Qwen by DeepSeek - Advanced reasoning in Qwen architecture across multiple sizes. Open-source models with strong coding (52.3%) and current knowledge."
  },
  {
    "Model": "R1 Lite Preview",
    "OperationalRank": "#75",
    "SafetyRank": "N/A",
    "Org.": "DeepSeek",
    "Size": "-",
    "Released": "20-Nov-24",
    "CodeLMArena": "-",
    "MathLiveBench": "-",
    "CodeLiveBench": "-",
    "Input Cost/M": "-",
    "Output Cost/M": "-",
    "CutoffKnowledge": null,
    "ContextLength": "-",
    "License": "Proprietary",
    "SafeResponses": "N/A",
    "UnsafeResponses": "N/A",
    "JailbreakingResistance": "N/A",
    "Description": "R1 Lite Preview is DeepSeek's experimental lightweight version of their advanced reasoning capabilities. As a preview model, it provides early access to cutting-edge reasoning features in a more accessible format for testing and evaluation purposes.",
    "Meta-description": "R1 Lite Preview by DeepSeek - Experimental lightweight version of advanced reasoning capabilities. Early access to cutting-edge reasoning features for testing and evaluation."
  }
]